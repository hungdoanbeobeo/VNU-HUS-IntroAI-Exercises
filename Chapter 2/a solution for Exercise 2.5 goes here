import itertools
import time
from typing import List, Set, Dict, Tuple, Union, Optional

class CNFTheoremProver:
    """
    A complete theorem prover for propositional logic in CNF using truth tables.
    
    Features:
    - Determines satisfiability (UNSAT, SAT, or TAUTOLOGY)
    - Counts interpretations and models
    - Supports multiple input formats
    - Provides detailed analysis and metrics
    """
    
    def __init__(self):
        self.variables = set()
        self.formula = []
        self.num_clauses = 0
        self.num_variables = 0
    
    def parse_cnf_formula(self, clauses: List[List[int]]) -> None:
        """Parse CNF formula from list of clauses."""
        self.formula = clauses
        self.variables = set()
        
        for clause in clauses:
            for literal in clause:
                self.variables.add(abs(literal))
        
        self.num_variables = len(self.variables)
        self.num_clauses = len(clauses)
    
    def parse_dimacs_format(self, dimacs_string: str) -> None:
        """Parse CNF formula from DIMACS format string."""
        lines = dimacs_string.strip().split('\n')
        clauses = []
        
        for line in lines:
            line = line.strip()
            if line.startswith('c') or not line:
                continue  # Skip comments and empty lines
            elif line.startswith('p cnf'):
                # Problem line: p cnf <num_vars> <num_clauses>
                parts = line.split()
                declared_vars = int(parts[2])
                declared_clauses = int(parts[3])
            else:
                # Clause line
                literals = list(map(int, line.split()))
                if literals and literals[-1] == 0:  # Remove trailing zero
                    literals = literals[:-1]
                if literals:  # Only add non-empty clauses
                    clauses.append(literals)
        
        self.parse_cnf_formula(clauses)
    
    def generate_all_assignments(self) -> List[Dict[int, bool]]:
        """Generate all 2^n possible truth assignments."""
        if not self.variables:
            return [{}]
            
        variables_list = sorted(list(self.variables))
        n_vars = len(variables_list)
        assignments = []
        
        for values in itertools.product([True, False], repeat=n_vars):
            assignment = dict(zip(variables_list, values))
            assignments.append(assignment)
            
        return assignments
    
    def evaluate_literal(self, literal: int, assignment: Dict[int, bool]) -> bool:
        """Evaluate truth value of a literal under assignment."""
        var = abs(literal)
        value = assignment.get(var, False)
        return value if literal > 0 else not value
    
    def evaluate_clause(self, clause: List[int], assignment: Dict[int, bool]) -> bool:
        """Evaluate truth value of a clause (disjunction) under assignment."""
        return any(self.evaluate_literal(literal, assignment) for literal in clause)
    
    def evaluate_formula(self, assignment: Dict[int, bool]) -> bool:
        """Evaluate truth value of CNF formula (conjunction) under assignment."""
        return all(self.evaluate_clause(clause, assignment) for clause in self.formula)
    
    def solve(self) -> Dict[str, Union[str, int, float, List[Dict[int, bool]]]]:
        """
        Solve the CNF satisfiability problem using truth table method.
        
        Returns comprehensive results including:
        - Satisfiability status
        - Number of interpretations and models
        - All satisfying assignments
        - Performance metrics
        """
        start_time = time.time()
        
        # Handle edge cases
        if not self.formula:
            return self._create_result('TAUTOLOGY', 1, 1, [{}], time.time() - start_time)
        
        if not self.variables:
            return self._create_result('UNSATISFIABLE', 1, 0, [], time.time() - start_time)
        
        # Generate and test all assignments
        assignments = self.generate_all_assignments()
        models = []
        
        for assignment in assignments:
            if self.evaluate_formula(assignment):
                models.append(assignment)
        
        solve_time = time.time() - start_time
        num_interpretations = len(assignments)
        num_models = len(models)
        
        # Determine status
        if num_models == 0:
            status = 'UNSATISFIABLE'
        elif num_models == num_interpretations:
            status = 'TAUTOLOGY'
        else:
            status = 'SATISFIABLE'
        
        return self._create_result(status, num_interpretations, num_models, models, solve_time)
    
    def _create_result(self, status: str, interpretations: int, models_count: int, 
                      models: List[Dict[int, bool]], solve_time: float) -> Dict:
        """Create standardized result dictionary."""
        return {
            'status': status,
            'num_interpretations': interpretations,
            'num_models': models_count,
            'satisfiability_ratio': models_count / interpretations if interpretations > 0 else 0,
            'models': models,
            'solve_time': solve_time,
            'formula_stats': self._get_formula_stats()
        }
    
    def _get_formula_stats(self) -> Dict[str, Union[int, float]]:
        """Get statistical information about the formula."""
        if not self.formula:
            return {'num_variables': 0, 'num_clauses': 0, 'avg_clause_length': 0}
        
        clause_lengths = [len(clause) for clause in self.formula]
        
        return {
            'num_variables': self.num_variables,
            'num_clauses': self.num_clauses,
            'min_clause_length': min(clause_lengths) if clause_lengths else 0,
            'max_clause_length': max(clause_lengths) if clause_lengths else 0,
            'avg_clause_length': sum(clause_lengths) / len(clause_lengths) if clause_lengths else 0,
            'total_literals': sum(clause_lengths)
        }
    
    def print_truth_table(self) -> str:
        """Generate formatted truth table."""
        if not self.variables:
            return "No variables in formula"
            
        variables_list = sorted(list(self.variables))
        assignments = self.generate_all_assignments()
        
        # Create header
        header = [f"x{var}" for var in variables_list] + ["Formula"]
        
        # Create table rows  
        rows = []
        for assignment in assignments:
            row = []
            for var in variables_list:
                row.append("T" if assignment[var] else "F")
            row.append("T" if self.evaluate_formula(assignment) else "F")
            rows.append(row)
        
        # Format table
        col_widths = [max(len(str(item)) for item in [header[i]] + [row[i] for row in rows]) 
                     for i in range(len(header))]
        
        # Build table string
        table_lines = []
        
        # Header
        header_row = " | ".join(f"{header[i]:^{col_widths[i]}}" for i in range(len(header)))
        table_lines.append(header_row)
        table_lines.append("-" * len(header_row))
        
        # Data rows
        for row in rows:
            row_str = " | ".join(f"{row[i]:^{col_widths[i]}}" for i in range(len(row)))
            table_lines.append(row_str)
            
        return "\n".join(table_lines)
    
    def print_results(self, result: Dict) -> str:
        """Print comprehensive formatted results."""
        lines = []
        lines.append("=" * 60)
        lines.append("CNF THEOREM PROVER - RESULTS")
        lines.append("=" * 60)
        
        # Formula representation
        lines.append("\nFORMULA (CNF):")
        for i, clause in enumerate(self.formula):
            clause_str = " ∨ ".join([f"x{abs(lit)}" if lit > 0 else f"¬x{abs(lit)}" 
                                   for lit in clause])
            lines.append(f"  Clause {i+1}: ({clause_str})")
        
        if len(self.formula) > 1:
            lines.append(f"  Combined: " + " ∧ ".join([f"({i+1})" for i in range(len(self.formula))]))
        
        # Statistics
        stats = result['formula_stats']
        lines.append("\nFORMULA STATISTICS:")
        lines.append(f"  Variables: {stats['num_variables']}")
        lines.append(f"  Clauses: {stats['num_clauses']}")
        if stats['num_clauses'] > 0:
            lines.append(f"  Avg clause length: {stats['avg_clause_length']:.2f}")
            lines.append(f"  Total literals: {stats['total_literals']}")
        
        # Main results
        lines.append("\nSATISFIABILITY ANALYSIS:")
        lines.append(f"  Status: {result['status']}")
        lines.append(f"  Total interpretations: {result['num_interpretations']}")
        lines.append(f"  Satisfying models: {result['num_models']}")
        lines.append(f"  Satisfiability ratio: {result['satisfiability_ratio']:.3f}")
        lines.append(f"  Computation time: {result['solve_time']:.6f} seconds")
        
        # Interpretation
        lines.append("\nINTERPRETATION:")
        if result['status'] == 'UNSATISFIABLE':
            lines.append("   The formula is UNSATISFIABLE (contradiction)")
            lines.append("     No truth assignment satisfies all clauses")
        elif result['status'] == 'TAUTOLOGY':
            lines.append("   The formula is a TAUTOLOGY (always true)")
            lines.append("     Every truth assignment satisfies all clauses")
        else:
            lines.append("    The formula is SATISFIABLE (contingency)")
            lines.append("     Some truth assignments satisfy all clauses")
        
        # Models
        if result['num_models'] > 0:
            lines.append("\nSATISFYING ASSIGNMENTS:")
            max_show = min(8, len(result['models']))
            for i in range(max_show):
                model = result['models'][i]
                assignment = ", ".join([f"x{var}={value}" for var, value in sorted(model.items())])
                lines.append(f"  Model {i+1}: {assignment}")
            
            if len(result['models']) > max_show:
                lines.append(f"  ... and {len(result['models']) - max_show} more models")
        
        return "\n".join(lines)

# Example usage and demonstration
def demonstrate_cnf_prover():
    """Demonstrate the CNF theorem prover with various examples."""
    
    examples = [
        {
            'name': 'Unsatisfiable Formula',
            'description': 'A contradiction: (x1) ∧ (¬x1)',
            'clauses': [[1], [-1]]
        },
        {
            'name': 'Tautology',
            'description': 'Always true: (x1 ∨ ¬x1)',
            'clauses': [[1, -1]]
        },
        {
            'name': 'Satisfiable Formula',
            'description': '(x1 ∨ x2) ∧ (¬x1 ∨ x2) ∧ (x1 ∨ ¬x2)',
            'clauses': [[1, 2], [-1, 2], [1, -2]]
        },
        {
            'name': 'Complex Example',
            'description': '3-variable formula with multiple clauses',
            'clauses': [[1, 2, -3], [-1, 3], [-2, 3], [1, -3]]
        }
    ]
    
    print("CNF Theorem Prover Demonstration")
    print("=" * 50)
    
    for i, example in enumerate(examples, 1):
        print(f"\n{i}. {example['name']}")
        print(f"   {example['description']}")
        print("-" * 50)
        
        prover = CNFTheoremProver()
        prover.parse_cnf_formula(example['clauses'])
        result = prover.solve()
        
        print(prover.print_results(result))
        
        if result['status'] != 'UNSATISFIABLE' and len(prover.variables) <= 3:
            print("\nTRUTH TABLE:")
            print(prover.print_truth_table())
        
        print("\n" + "=" * 60)

if __name__ == "__main__":
    demonstrate_cnf_prover()
